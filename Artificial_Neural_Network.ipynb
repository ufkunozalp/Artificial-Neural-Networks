{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp7i_jzAKGPy"
      },
      "source": [
        "<h1><center><b> Acquired Intelligence & Adaptive Behaviour </b></center></h1>\n",
        "<h2><center><i>Artificial Neural Networks (Lab Sheet 01) </i></center></h2>\n",
        "\n",
        "\n",
        "> _If you find any bugs in this notebook, please contact `kagioulis.efstathios@gmail.com`_\n",
        "\n",
        "Welcome to the first _Acquired Intelligence & Adaptive Behaviour_ lab session. In this notebook, we will be learning how to implement artifical neural networks in [PyTorch](https://pytorch.org/). The notebook assumes basic familiarity with `python` and `pytorch`. Please refer to the course lecture __Intro to Python and Pytorch__ for a gentle introduction to the relevant concepts. \n",
        "\n",
        "\n",
        "### _Goals for this notebook_\n",
        " 1. Get familiar with `pytorch` \n",
        " 2. Manually implement a feed-forward neural network to solve NOT / AND / OR gates\n",
        " 3. Use backpropagation to solve XOR gates\n",
        " 4. Experiment with recurrent neural networks\n",
        " 5. Use backproagation to learn a sine wave\n",
        "\n",
        "### _Table of Contents_\n",
        "- [1. Setting up your environment ](#setup)  \n",
        "- [2. Building your first neural network ](#feedforward)  \n",
        "- [3. Implementing logic gates](#3)  \n",
        "- [4. Training a neural network](#4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWEgE2frLmQf"
      },
      "source": [
        "## 1. Setting up your environment <a id=\"setup\"></a> \n",
        "\n",
        "I highly recommend using [`Google colab`](https://colab.research.google.com) for these lab sessions. It will save you having to install packages and give you access to GPU acceleration. I will have only tested these notebooks on Google colab, so please only run locally if you are comfortable with `Python`. \n",
        "\n",
        "For a basic introduction to `Google colab`, please refer to this [link](https://colab.research.google.com/), where you will find a number of introductory notebooks. I recommend saving a copy of this notebook in Google drive (`File > Save a copy in Drive`).\n",
        "\n",
        "__Some tips__: `Python` notebooks are extremely useful for quick development. However, [they have some notable downsides](https://docs.google.com/presentation/d/1n2RlMdmv1p25Xy5thJUhkKGvjtV-dkAIsUXP-AL4ffI/preview). Variables and state are shared across cells, and this will inevitably cause you a range of hard to detect errors. If you run into an issue which you can't solve, try doing `Runtime > Restart and run all`, which will reset the environment and run your cells in order. \n",
        "\n",
        "## Importing packages\n",
        "\n",
        "If you are using `Google colab`, you will not need to install anything. If you are running this notebook locally (not recommended), you will need to install `matplotlib`, `numpy` and `pytorch`:\n",
        "\n",
        "```bash\n",
        "pip install matplotlib\n",
        "pip install numpy\n",
        "pip install torch \n",
        "```\n",
        "\n",
        "To check you have the correct packages installed, run the cell below, which will import the packages so that they can be used later:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIwSn0ZzatQh",
        "outputId": "b854b51b-2a09-4c55-b69f-71429b31914f"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import torch\n",
        "print(\"Packages successfully imported!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Packages successfully imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDwPFV-abXtN"
      },
      "source": [
        "## 2. Building your first neural network <a id=\"feedforward\"></a> \n",
        "\n",
        "Implementing artifical neural networks can be broken down into two steps, __(1)__ constructing your neural network and __(2)__ learning the weights of your neural network. In this first section, we are going to be dealing with __(1)__. \n",
        "\n",
        "I will assume that you are already familiar with the basics of neural networks. If you are not, please refer to the lecture slides. To recap, neural networks involve some input $x$, some weights $W$, optionally, a bias $b$, an activation funtion $f$, and an output $y$:\n",
        "\n",
        "$$ \n",
        "y = f(W \\cdot x + b)\n",
        "$$\n",
        "\n",
        "Pictorially, this can be represented as:\n",
        "\n",
        "<center><img src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-981-10-5687-1_8/MediaObjects/430883_1_En_8_Fig2_HTML.gif\" width=\"500\"></center>\n",
        "\n",
        "When constructing a neural network, the first question to ask is: how are each of these components represented in code? Let us look at each in more detail:\n",
        "\n",
        "| Component      | Description |\n",
        "| ----------- | ----------- |\n",
        "| __Input $x$__      | $1 \\times N_{\\mathrm{input}}$ vector, where $N_{\\mathrm{input}}$ is the size of your input       |\n",
        "| __Weights $W$__   | $N_{\\mathrm{input}} \\times N_{\\mathrm{output}}$ matrix, where $N_{\\mathrm{output}}$ is the size of your output. $W_{ij}$ will be the weight connecting input $i$ to output $j$ |\n",
        "|__Bias $b$__| $1 \\times N_{\\mathrm{output}}$ vector |\n",
        "|__Activation function $f$__| Any differentiable linear or non-linear function which takes $W \\cdot x + b$ (a vector of size $1 \\times N_{\\mathrm{output}}$) and returns a vector of the same size  |\n",
        "|__Output $y$__| $1 \\times N_{\\mathrm{output}}$ vector|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toKCtcDZnzRV"
      },
      "source": [
        "> **Task**: In the code below, I have provided some random input $x$ and an activation function $f$. _**You must to construct a matrix of random weights and a vector of random biases which have the correct size.**_\n",
        "\n",
        "**Tips**: The code `torch.mm(x, W)` implements $W \\cdot x$ (`mm` stands for matrix multiply). Check out this [link](https://towardsdatascience.com/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c) for more information of matrix multiplication. You can use `torch.rand` to generate random matrices and vectors, see this [link](https://pytorch.org/docs/stable/generated/torch.rand.html).\n",
        "\n",
        "You can safely ignore the activation function for now, we will use this in the following example. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qo1asCgdKuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2678d227-3d7b-4f98-a83d-aa4c2d809f5b"
      },
      "source": [
        "num_input = 7\n",
        "num_output = 5\n",
        "\n",
        "# Input\n",
        "x = torch.rand(1, num_input)\n",
        "# Weights (todo)\n",
        "W = torch.rand(num_input, num_output)\n",
        "# biases (todo)\n",
        "b = torch.rand(1, num_output)\n",
        "\n",
        "# Activation function\n",
        "def f(inp):\n",
        "    inp[inp >= 0] = 1\n",
        "    inp[inp < 0] = 0\n",
        "    return inp\n",
        "\n",
        "# Predict output\n",
        "y = f(torch.mm(x, W) + b)\n",
        "\n",
        "# Check solution\n",
        "assert list(y.size()) == [1, num_output], f\"Incorrect output size ({y.size()})\"\n",
        "print(\"Well done, your weights and biases are the correct size!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done, your weights and biases are the correct size!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89wRVG6iTcsU"
      },
      "source": [
        "## 3. Implementing logic gates <a id=\"3\"></a> \n",
        "\n",
        "The next step is to make our neural network do something interesting. Neural networks encode knowledge in the weights and biases. These are usually learnt, but for simple problems, we can construct them by hand. A classic problem is implementing [logic gates](https://en.wikipedia.org/wiki/Logic_gate). \n",
        "\n",
        "### 3a. `AND` gate\n",
        "\n",
        "The AND gate is defined as follows:\n",
        "\n",
        "| INPUT    | OUTPUT |\n",
        "| ----------- | ----------- |\n",
        "|0  / 0 | 0 |\n",
        "|0  / 1 | 0 |\n",
        "|1  / 0 | 0 |\n",
        "|1  / 1 | 1 |\n",
        "\n",
        "In other words, if the input is both one, output one, otherwise, output zero. What does the neural network representation of this problem look like? We can see that our network will take two inputs ($N_{\\mathrm{input}} = 2$) and output one number ($N_{\\mathrm{output}} = 1$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufDWUNIOV5PC"
      },
      "source": [
        "> **Task**: In the code below, I have provided inputs and outputs which represent the `AND` problem. _**You must to construct a matrix of  weights and a vector of biases which solve the problem.**_\n",
        "\n",
        "**Tips**: The activation function I have provided implements a binary threshold. If $W\\cdot x + b \\geq 0$, then it outputs 1, and if $W\\cdot x + b < 0$, it outputs 0. \n",
        "\n",
        "There are several ways to construct matrices by hand. The simplest is to pass a list of lists into `torch.tensor` (which will allow it to be used within `pytorch`).\n",
        "\n",
        "A $4 \\times 2$ matrix can be constructed using:\n",
        "\n",
        "```python\n",
        "torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "``` \n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "0 & 0 \\\\\n",
        "0 & 1 \\\\\n",
        "1 & 0 \\\\\n",
        "1 & 1 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Alternatively, you could get the same result by doing:\n",
        "```python\n",
        "torch.tensor([[0., 0., 1., 1.], [0., 1., 0., 1.]]).T\n",
        "``` \n",
        "\n",
        "where `.T` is the [_transpose_](https://en.wikipedia.org/wiki/Transpose).\n",
        "\n",
        "You'll also notice that there is `.unsqueeze(0)` when getting each example. This adds an extra leading dimension, e.g. converts a vector of size `[4]` to one of size `[1 x 4]`. This is necessary for the matrix multiply. \n",
        "\n",
        "Finally, you may run into the following error:\n",
        "\n",
        "```python\n",
        "RuntimeError: expected scalar type Float but found Long\n",
        "```\n",
        "`Pytorch` is very strict about the types of data you have inside a tensor (e.g. is it an `int`, a `float`, etc). Most of the time you will want to use float. There are several ways to achieve this: you can put decimal places infront of your numbers (e.g. `[3.0, 2.0]` instead of `[3, 2]`), or you can call the function `.float()` on any tensor to convert it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV8OIVmHV8JQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b2e828-492b-42b2-bf89-e5f94c9f62cf"
      },
      "source": [
        "# Define our data for AND problem\n",
        "input_data = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "output_data = torch.tensor([[0.], [0.], [0.], [1.]])\n",
        "print(f\"We have {input_data.size(0)} examples\")\n",
        "print(f\"Input is size {input_data.size(1)} and output is size {output_data.size(1)}\")\n",
        "\n",
        "# Define our weights and biases (todo)\n",
        "W = torch.tensor([[2.], [2.]]) \n",
        "b = torch.tensor([[-3.]])\n",
        "assert list(W.size()) == [2, 1], f\"Weights are incorrect size ({W.size()})\"\n",
        "assert list(b.size()) == [1, 1], f\"Biases are incorrect size ({b.size()})\"\n",
        "\n",
        "# Activation function\n",
        "def f(inp):\n",
        "    inp[inp >= 0] = 1\n",
        "    inp[inp < 0] = 0\n",
        "    return inp\n",
        "\n",
        "# Loop over each example\n",
        "for i in range(input_data.size(0)):\n",
        "    # Get example `i` (and unsqueeze to [1, 2] and [1, 1])\n",
        "    x = input_data[i].unsqueeze(0)\n",
        "    y = output_data[i].unsqueeze(0)\n",
        "\n",
        "    # Predict output \n",
        "    y_hat = f(torch.mm(x, W) + b)\n",
        "\n",
        "    # Check predictions are correct\n",
        "    print(f\"Prediction {y_hat}, desired output {y}\")\n",
        "    assert (y == y_hat), f\"{y_hat} does not equal {y}\"\n",
        "\n",
        "print(\"Well done, your weights and biases are correct!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 4 examples\n",
            "Input is size 2 and output is size 1\n",
            "Prediction tensor([[0.]]), desired output tensor([[0.]])\n",
            "Prediction tensor([[0.]]), desired output tensor([[0.]])\n",
            "Prediction tensor([[0.]]), desired output tensor([[0.]])\n",
            "Prediction tensor([[1.]]), desired output tensor([[1.]])\n",
            "Well done, your weights and biases are correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3YEZxBTdiIp"
      },
      "source": [
        "### 3b. `OR` gate\n",
        "\n",
        "The OR gate is defined as follows:\n",
        "\n",
        "| INPUT    | OUTPUT |\n",
        "| ----------- | ----------- |\n",
        "|0  / 0 | 0 |\n",
        "|0  / 1 | 1 |\n",
        "|1  / 0 | 1 |\n",
        "|1  / 1 | 1 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVitPijnd9BE"
      },
      "source": [
        "> **Task**: In the code below, I have provided inputs and outputs which represent the `OR` problem. _**You must to construct a matrix of  weights and a vector of biases which solve the problem.**_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sfhNe55d-Ni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e815d94-73bc-45be-8c06-ed95e5b6bc69"
      },
      "source": [
        "# Define our data for OR problem\n",
        "input_data = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "output_data = torch.tensor([[0.], [1.], [1.], [1.]])\n",
        "\n",
        "# Define our weights and biases (todo)\n",
        "W = torch.tensor([[1.], [1.]]) \n",
        "b = torch.tensor([[-0.1]])\n",
        "assert list(W.size()) == [2, 1], f\"Weights are incorrect size ({W.size()})\"\n",
        "assert list(b.size()) == [1, 1], f\"Biases are incorrect size ({b.size()})\"\n",
        "\n",
        "# Activation function\n",
        "def f(inp):\n",
        "    inp[inp >= 0] = 1\n",
        "    inp[inp < 0] = 0\n",
        "    return inp\n",
        "\n",
        "# Loop over each example\n",
        "for i in range(input_data.size(0)):\n",
        "    # Get example `i` (and unsqueeze to [1, 2] and [1, 1])\n",
        "    x = input_data[i].unsqueeze(0)\n",
        "    y = output_data[i].unsqueeze(0)\n",
        "\n",
        "    # Predict output \n",
        "    y_hat = f(torch.mm(x, W) + b)\n",
        "\n",
        "    # Check predictions are correct\n",
        "    print(f\"Prediction {y_hat}, desired output {y}\")\n",
        "    assert (y == y_hat), f\"{y_hat} does not equal {y}\"\n",
        "\n",
        "print(\"Well done, your weights and biases are correct!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction tensor([[0.]]), desired output tensor([[0.]])\n",
            "Prediction tensor([[1.]]), desired output tensor([[1.]])\n",
            "Prediction tensor([[1.]]), desired output tensor([[1.]])\n",
            "Prediction tensor([[1.]]), desired output tensor([[1.]])\n",
            "Well done, your weights and biases are correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNA3Eq3Sebws"
      },
      "source": [
        "### 3c. `NOR` gate\n",
        "\n",
        "The NOR gate is defined as follows:\n",
        "\n",
        "| INPUT    | OUTPUT |\n",
        "| ----------- | ----------- |\n",
        "|0  / 0 | 1 |\n",
        "|0  / 1 | 0 |\n",
        "|1  / 0 | 0 |\n",
        "|1  / 1 | 0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYRr7-TOleWM"
      },
      "source": [
        "> **Task**: In the code below, I have provided inputs and outputs which represent the `NOT` problem. _**You must to construct a matrix of  weights and a vector of biases which solve the problem.**_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH6QqmQiewpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915d2e5a-ce13-4740-c030-40174e168dac"
      },
      "source": [
        "# Define our data for NOR problem\n",
        "input_data = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "output_data = torch.tensor([[1.], [0.], [0.], [0.]])\n",
        "\n",
        "# Define our weights and biases (todo)\n",
        "W = torch.tensor([[-1.], [-1.]])\n",
        "b = torch.tensor([[0.]])\n",
        "assert list(W.size()) == [2, 1], f\"Weights are incorrect size ({W.size()})\"\n",
        "assert list(b.size()) == [1, 1], f\"Biases are incorrect size ({b.size()})\"\n",
        "\n",
        "# Activation function\n",
        "def f(inp):\n",
        "    inp[inp >= 0] = 1\n",
        "    inp[inp < 0] = 0\n",
        "    return inp\n",
        "\n",
        "# Loop over each example\n",
        "for i in range(input_data.size(0)):\n",
        "    # Get example `i` (and unsqueeze to [1, 2] and [1, 1])\n",
        "    x = input_data[i].unsqueeze(0)\n",
        "    y = output_data[i].unsqueeze(0)\n",
        "\n",
        "    # Predict output \n",
        "    y_hat = f(torch.mm(x, W) + b)\n",
        "\n",
        "    # Check predictions are correct\n",
        "    print(f\"Input: {x}, Prediction {y_hat}, desired output {y}\")\n",
        "    assert (y == y_hat), f\"{y_hat} does not equal {y}\"\n",
        "\n",
        "print(\"Well done, your weights and biases are correct!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([[0., 0.]]), Prediction tensor([[1.]]), desired output tensor([[1.]])\n",
            "Input: tensor([[0., 1.]]), Prediction tensor([[0.]]), desired output tensor([[0.]])\n",
            "Input: tensor([[1., 0.]]), Prediction tensor([[0.]]), desired output tensor([[0.]])\n",
            "Input: tensor([[1., 1.]]), Prediction tensor([[0.]]), desired output tensor([[0.]])\n",
            "Well done, your weights and biases are correct!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dunw6h1nfAGb"
      },
      "source": [
        "## 4. Training a neural network <a id=\"4\"></a> \n",
        "\n",
        "So far, we have been encoding knowledge by hand. In this section, we are going to implement learning. \n",
        " Instead, we will be using a multi-layer perceptron:\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/3446/1*-IPQlOd46dlsutIbUq1Zcw.png\" width=\"500\"></center>\n",
        "\n",
        "For our problem, we will be using two layers, which means we have two sets of weights and biases. Our first step will be to construct a two layer neural network, and then we will cover how to learn the weights and biases in the following section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lEe5VeHlbOM"
      },
      "source": [
        "> **Task**: In the code below, I have provided inputs and outputs which represent the `XOR` problem. _**You must to construct two random matrices of weights and two random vectors of biases which are of the correct size, and fill in the `predict` function**_.\n",
        "\n",
        "**Tips**: Note that we still have the same amount of inputs (2), the same amount of outputs (1). But what is the output for the first layer, and what is the input for the second layer? This is what we will refer to as the number of _hidden nodes_, and you can pick any number you like. \n",
        "\n",
        "Below, I provide some \"pseudocode\" for what the `predict` function should look like: \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    h &= f(W_1\\cdot x + b_1) \\\\\n",
        "    y &= W_2 \\cdot h + b_2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "You have a number of design decisions which you can evaluate in the next section. For instance, what activation function to use? How many hidden nodes? Do extra layers help? What happens if we have an activation function on the output layer?\n",
        "\n",
        "Note `pytorch` includes a range of activation functions, including `torch.sigmoid`, `torch.relu`, `torch.tanh`. You can use these as follows:\n",
        "\n",
        "```python\n",
        "out = torch.sigmoid(torch.mm(x, W) + b)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqniZNzYl6Yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6147e8-4f78-4461-dbfe-de00d969e3a8"
      },
      "source": [
        "# Define our data for XOR problem\n",
        "input_data = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "output_data = torch.tensor([[0.], [1.], [1.], [0.]])\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "\n",
        "# Define weights & biases for first layer (todo)\n",
        "W_1 = torch.rand(input_size, hidden_size)\n",
        "b_1 = torch.rand(1, 1)\n",
        "# Define weights & biases for second layer (todo)\n",
        "W_2 = torch.rand(hidden_size, 1)\n",
        "b_2 = torch.rand(1, 1)\n",
        "\n",
        "# Define our predict function (todo)\n",
        "def predict(x, W_1, W_2, b_1, b_2):\n",
        "    h = torch.sigmoid(torch.mm(x, W_1) + b_1)\n",
        "    output = torch.mm(h, W_2) + b_2\n",
        "    return output\n",
        "\n",
        "# Loop over examples\n",
        "for i in range(input_data.size(0)):\n",
        "    # Get example `i` (and unsqueeze to [1, 2] and [1, 1])\n",
        "    x = input_data[i].unsqueeze(0)\n",
        "\n",
        "    # Make a prediction\n",
        "    y_hat = predict(x, W_1, W_2, b_1, b_2)\n",
        "    assert (list(y_hat.size()) == [1, 1]), f\"incorrect output size ({y_hat.size()})\"\n",
        "\n",
        "print(\"Well done, you weights and biases were the correct size!\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done, you weights and biases were the correct size!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjzw22ZZo5I6"
      },
      "source": [
        "### 4b. Training loop\n",
        "\n",
        "When using `pytorch`, you don't have to implement learning yourself. It uses [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) to implement backpropagation for you. \n",
        "\n",
        "Here, we introduce two new concepts:\n",
        "\n",
        "**Optimizers**: `Pytorch` use something called optimizers. These will collect gradients as you do computations and then perform optimisation algorithms (such as stochastic gradient descent) to update your parameters (weights and biases). Here is an example of of setting up an optimizer:\n",
        "\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.SGD([W, b], lr=0.01)\n",
        "```\n",
        "\n",
        "The first argument is a list of parameters which you wish to optimise (e.g., weights and biases). The second is the _learning rate_. \n",
        "\n",
        "**Loss function**: The loss function provides a measure of \"how wrong\" a prediction was. An example is the [mean-squared error](https://en.wikipedia.org/wiki/Mean_squared_error). `Pytorch` has a number of these packaged, for instance:\n",
        "\n",
        "```python\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "```\n",
        "\n",
        "which can then be called using:\n",
        "\n",
        "```python\n",
        "loss = loss_fn(pred, y)\n",
        "```\n",
        "where `pred` was the prediction of your network. \n",
        "\n",
        "There are four steps to calculating gradients and updating weights and biases, detailed below (these must be performed in order). Please refer to the introductory lecture for more information.\n",
        "\n",
        "- **Clear gradients**: This is an artefact of the way `pytorch` works. Before calculating new gradients, you need to clear out gradients. This can be achieved by calling `optimizer.zero_grad()`\n",
        "- **Predict output**: This is the step we covered in the previous section\n",
        "- **Calculate loss**: How wrong was my prediction? This can be achieved with `loss_fn(prediction, true)`\n",
        "- **Calculate gradients**: What are the gradients of my loss with respect to my weights and biases? This can be achieved with `loss.backward()`\n",
        "- **Update weights and biases**: Once we know the gradients, we need to use them to update the weights and biases. This can be achieved with `optimizer.step()`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhP0fqp02pVR"
      },
      "source": [
        "> **Task**: In the code below, I have provided inputs and outputs which represent the `XOR` problem. Use your weights, biases and predict function from the previous task _**You must add code to make a prediction, get the loss, calculate the gradients, and update the weights and biases**_.\n",
        "\n",
        "\n",
        "**NOTE**: We have to tell `pytorch` which variables we want gradients for. We do this by wrapping them in `nn.Parameter`, e.g.\n",
        "\n",
        "```python\n",
        "w = nn.Parameter(torch.rand(2,3))\n",
        "```\n",
        "\n",
        "Failure to do this will give you the following error:\n",
        "\n",
        "```python\n",
        "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
        "```\n",
        "\n",
        "Also note that we have to perform these updates multiple times, stochastic gradient descent only update the weights a little bit each time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1yxdfy3pCiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b45cf05-42b3-499c-c861-98f7126aa033"
      },
      "source": [
        "# Provides extra neural network functions\n",
        "import torch.nn as nn\n",
        "# Provides optimizers\n",
        "import torch.optim as optim\n",
        "\n",
        "# number of epochs\n",
        "num_epochs = 10000\n",
        "\n",
        "# Define our data for XOR problem\n",
        "input_data = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "output_data = torch.tensor([[0.], [1.], [1.], [0.]])\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "\n",
        "# Define weights & biases for first layer (todo)\n",
        "W_1 = torch.rand(input_size, hidden_size)\n",
        "b_1 = torch.rand(1, 1)\n",
        "# Define weights & biases for second layer (todo)\n",
        "W_2 = torch.rand(hidden_size, 1)\n",
        "b_2 = torch.rand(1, 1)\n",
        "\n",
        "x = nn.Parameter(x)\n",
        "W_1 = nn.Parameter(W_1)\n",
        "W_2 = nn.Parameter(W_2)\n",
        "b_1 = nn.Parameter(b_1)\n",
        "b_2 = nn.Parameter(b_2)\n",
        "\n",
        "# Setup our loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Setup our optimizer\n",
        "optimizer = optim.SGD([W_1, W_2, b_1, b_2], lr=0.01)\n",
        "\n",
        "# Define our predict function (todo)\n",
        "def predict(x, W_1, W_2, b_1, b_2):\n",
        "    h = torch.sigmoid(torch.mm(x, W_1) + b_1)\n",
        "    output = torch.mm(h, W_2) + b_2\n",
        "    return output\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(input_data.size(0)):\n",
        "        # Get example `i` (and unsqueeze to [1, 2] and [1, 1])\n",
        "        x = input_data[i].unsqueeze(0)\n",
        "        y = output_data[i].unsqueeze(0)\n",
        "\n",
        "        \n",
        "        # Clear gradients (todo)\n",
        "        optimizer.zero_grad()\n",
        "        # Predict outputs (todo)\n",
        "        y_hat = predict(x, W_1, W_2, b_1, b_2)\n",
        "        # Calculate loss (todo)\n",
        "        loss = loss_fn(y_hat, y)\n",
        "        # Calculate gradients (todo)\n",
        "        loss.backward()\n",
        "        # Update weights (todo)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Test our network\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Testing network @ epoch {epoch}\")\n",
        "        for i in range(input_data.size(0)):\n",
        "            # Make a prediction\n",
        "            x = input_data[i].unsqueeze(0)\n",
        "            y = output_data[i].unsqueeze(0)\n",
        "            y_hat = predict(x, W_1, W_2, b_1, b_2)\n",
        "            # Print result\n",
        "            print(\"Input:{} Target: {} Predicted:[{}] Error:[{}]\".format(\n",
        "                x.data.numpy(),\n",
        "                y.data.numpy(),\n",
        "                np.round(y_hat.data.numpy(), 4),\n",
        "                np.round(y.data.numpy() - y_hat.data.numpy(), 4)\n",
        "            ))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing network @ epoch 0\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[1.3249]]] Error:[[[-1.3249]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[1.4648]]] Error:[[[-0.4648]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[1.3905]]] Error:[[[-0.3905]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[1.5169]]] Error:[[[-1.5169]]]\n",
            "Testing network @ epoch 1000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[0.4725]]] Error:[[[-0.4725]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.4876]]] Error:[[[0.5124]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.5069]]] Error:[[[0.4931]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[0.5151]]] Error:[[[-0.5151]]]\n",
            "Testing network @ epoch 2000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[0.4452]]] Error:[[[-0.4452]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.4791]]] Error:[[[0.5209]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.5212]]] Error:[[[0.4788]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[0.5309]]] Error:[[[-0.5309]]]\n",
            "Testing network @ epoch 3000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[0.3798]]] Error:[[[-0.3798]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.4804]]] Error:[[[0.5196]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.5564]]] Error:[[[0.4436]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[0.5506]]] Error:[[[-0.5506]]]\n",
            "Testing network @ epoch 4000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[0.2308]]] Error:[[[-0.2308]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.5335]]] Error:[[[0.4665]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.6459]]] Error:[[[0.3541]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[0.5341]]] Error:[[[-0.5341]]]\n",
            "Testing network @ epoch 5000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[0.1112]]] Error:[[[-0.1112]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.7715]]] Error:[[[0.2285]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.7767]]] Error:[[[0.2233]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[0.3005]]] Error:[[[-0.3005]]]\n",
            "Testing network @ epoch 6000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[0.0311]]] Error:[[[-0.0311]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.9575]]] Error:[[[0.0425]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.9547]]] Error:[[[0.0453]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[0.0532]]] Error:[[[-0.0532]]]\n",
            "Testing network @ epoch 7000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[0.004]]] Error:[[[-0.004]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.9949]]] Error:[[[0.0051]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.9945]]] Error:[[[0.0055]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[0.0063]]] Error:[[[-0.0063]]]\n",
            "Testing network @ epoch 8000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[0.0005]]] Error:[[[-0.0005]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.9994]]] Error:[[[0.0006]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.9994]]] Error:[[[0.0006]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[0.0007]]] Error:[[[-0.0007]]]\n",
            "Testing network @ epoch 9000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[1.e-04]]] Error:[[[-1.e-04]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[0.9999]]] Error:[[[1.e-04]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[0.9999]]] Error:[[[1.e-04]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[1.e-04]]] Error:[[[-1.e-04]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrIQ3iOTm8aK"
      },
      "source": [
        "## 4c. Solve XOR \n",
        "\n",
        " We are going to try and learn the `XOR` logic gate, defined by:\n",
        "\n",
        "| INPUT    | OUTPUT |\n",
        "| ----------- | ----------- |\n",
        "|0  / 0 | 0 |\n",
        "|0  / 1 | 1 |\n",
        "|1  / 0 | 1 |\n",
        "|1  / 1 | 0 |\n",
        "\n",
        "> **Task**: In the code below, I have provided inputs and outputs which represent the `XOR` problem. _**You must train a neural network to solve this task**_. Explore how the number of layers, number of hidden nodes, the activation functions and the learning rate influence learning. Use what you learned in the lab sheet.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIW4Cd1lnHqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79b2cde-61d4-426c-a6b7-0b88bd472984"
      },
      "source": [
        "# Provides extra neural network functions\n",
        "import torch.nn as nn\n",
        "# Provides optimizers\n",
        "import torch.optim as optim\n",
        "\n",
        "# number of epochs\n",
        "num_epochs = 10000\n",
        "\n",
        "# Define our data for XOR problem\n",
        "input_data = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
        "output_data = torch.tensor([[0.], [1.], [1.], [0.]])\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 8\n",
        "\n",
        "# Define weights & biases for first layer (todo)\n",
        "W_1 = torch.rand(input_size, hidden_size)\n",
        "b_1 = torch.rand(1, 1)\n",
        "# Define weights & biases for second layer (todo)\n",
        "W_2 = torch.rand(hidden_size, hidden_size)\n",
        "b_2 = torch.rand(1, 1)\n",
        "# Define weights & biases for the third layer (todo)\n",
        "W_3 = torch.rand(hidden_size, hidden_size)\n",
        "b_3 = torch.rand(1, 1)\n",
        "# Define weights & biases for the fourth layer (todo)\n",
        "W_4 = torch.rand(hidden_size, 1)\n",
        "b_4 = torch.rand(1, 1)\n",
        "\n",
        "\n",
        "x = nn.Parameter(x)\n",
        "W_1 = nn.Parameter(W_1)\n",
        "b_1 = nn.Parameter(b_1)\n",
        "W_2 = nn.Parameter(W_2)\n",
        "b_2 = nn.Parameter(b_2)\n",
        "W_3 = nn.Parameter(W_3)\n",
        "b_3 = nn.Parameter(b_3)\n",
        "W_4 = nn.Parameter(W_4)\n",
        "b_4 = nn.Parameter(b_4)\n",
        "\n",
        "# Setup our loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Setup our optimizer\n",
        "optimizer = optim.SGD([W_1, W_2, W_3, b_1, b_2, b_3], lr=3)\n",
        "\n",
        "# Define our predict function (todo)\n",
        "def predict(x, W_1, W_2, W_3, W_4, b_1, b_2, b_3, b_4):\n",
        "    z1 = torch.mm(x, W_1) + b_1\n",
        "    h1 = torch.tanh(z1)\n",
        "    z2 = torch.mm(h1, W_2) + b_2\n",
        "    h2 = torch.tanh(z2)\n",
        "    z3 = torch.mm(h2, W_3) + b_2\n",
        "    h3 = torch.tanh(z3) \n",
        "    output = torch.mm(h3, W_4) + b_4\n",
        "    return output\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(input_data.size(0)):\n",
        "        # Get example `i` (and unsqueeze to [1, 2] and [1, 1])\n",
        "        x = input_data[i].unsqueeze(0)\n",
        "        y = output_data[i].unsqueeze(0)\n",
        "\n",
        "        \n",
        "        # Clear gradients (todo)\n",
        "        optimizer.zero_grad()\n",
        "        # Predict outputs (todo)\n",
        "        y_hat = predict(x, W_1, W_2, W_3, W_4, b_1, b_2, b_3, b_4)\n",
        "        # Calculate loss (todo)\n",
        "        loss = loss_fn(y_hat, y)\n",
        "        # Calculate gradients (todo)\n",
        "        loss.backward()\n",
        "        # Update weights (todo)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Test our network\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Testing network @ epoch {epoch}\")\n",
        "        for i in range(input_data.size(0)):\n",
        "            # Make a prediction\n",
        "            x = input_data[i].unsqueeze(0)\n",
        "            y = output_data[i].unsqueeze(0)\n",
        "            y_hat = predict(x, W_1, W_2, W_3, W_4, b_1, b_2, b_3, b_4)\n",
        "            # Print result\n",
        "            print(\"Input:{} Target: {} Predicted:[{}] Error:[{}]\".format(\n",
        "                x.data.numpy(),\n",
        "                y.data.numpy(),\n",
        "                np.round(y_hat.data.numpy(), 4),\n",
        "                np.round(y.data.numpy() - y_hat.data.numpy(), 4)\n",
        "            ))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing network @ epoch 0\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 1000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 1100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 1200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 1300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 1400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-2.7786]]] Error:[[[3.7786]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-2.7786]]] Error:[[[2.7786]]]\n",
            "Testing network @ epoch 1500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 1600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 1700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 1800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 1900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 2900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 3900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 4900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 5900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 6900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 7900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 8900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9000\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9100\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9200\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9300\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9400\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9500\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9600\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9700\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9800\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Testing network @ epoch 9900\n",
            "Input:[[0. 0.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n",
            "Input:[[0. 1.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 0.]] Target: [[1.]] Predicted:[[[-0.4723]]] Error:[[[1.4723]]]\n",
            "Input:[[1. 1.]] Target: [[0.]] Predicted:[[[-0.4723]]] Error:[[[0.4723]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2Qbn5rTU-UF"
      },
      "source": [
        "## 5. Recurrent Neural Networks\n",
        "\n",
        "In this section, we will implement a recurrent neural network. A neural network contains recurrent dynamics, e.g. it maintains some state $x$ which evolves over time:\n",
        "\n",
        "$$\n",
        "x_{t + 1} =  f(W \\cdot x_t)\n",
        "$$\n",
        "\n",
        "> **Task**: In the code below, I have provided a basic recurrent neural network. We also add some external input $I$: \n",
        "\n",
        "$$\n",
        "x_{t + 1} =  f(W \\cdot x_t + I)\n",
        "$$\n",
        "\n",
        "> Your task is to play with the weights, activation function and inputs. Plot the dynamics: can you find attractors and chaos?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGeFkrL-MlOR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "031a9140-66e3-494a-da2c-025cd29fca05"
      },
      "source": [
        "num_iterations = 100\n",
        "num_nodes = 4\n",
        "\n",
        "weights = torch.randn(num_nodes, num_nodes) * 1\n",
        "\n",
        "# activations over time\n",
        "x = torch.zeros(num_nodes, num_iterations)\n",
        "# init conditions\n",
        "x[0, 0] = -1\n",
        "x[1, 0] = 1\n",
        "\n",
        "# setup random input\n",
        "conf = torch.tensor(np.random.choice([0, 1.0], size=(num_nodes)))\n",
        "pulse_time = 50\n",
        "pulse_dur = 10\n",
        "mag = 3.0\n",
        "impulse = 0\n",
        "\n",
        "for t in range(1, num_iterations):\n",
        "    # update activations\n",
        "    x[:, t] = torch.tanh(torch.mm(x[:, t-1].unsqueeze(0), weights) + impulse)\n",
        "\n",
        "    # set input\n",
        "    if t > pulse_time and t < (pulse_time + pulse_dur):\n",
        "        impulse = mag * conf\n",
        "    else:\n",
        "        impulse = 0\n",
        "\n",
        "# plot\n",
        "_, ax = plt.subplots(1, 1)\n",
        "for n in range(num_nodes):\n",
        "    ax.plot(range(num_iterations), x[n, :])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGpyyDcmB-oD"
      },
      "source": [
        "## 5.b Sequence learning __(optional)__\n",
        "\n",
        "When dealing with recurrent neural networks, we generally consider learning _sequences_ of data. For instance, how does the stock market fall and rise? By leatning recurrent neural networks of stock history, we can try to predict how it will act in the future. \n",
        "\n",
        "Let $\\mathbf{y}$ denote a sequence of stock prices, over 5 days: $\\mathbf{y} = \\{y_1, y_2, y_3, y_4, y_5\\}$ (we will use $y_t$ to denote the value of $y$ at time $t$). A recurrent neural network will predict:\n",
        "\n",
        "$$\n",
        "x_{t+1} = f(W^a[x_t \\ y_t]) \\\\\n",
        "y_{t+1} = W^b x_{t+1}\n",
        "$$\n",
        "\n",
        "where $x$ is the hidden state.\n",
        "\n",
        "> **Task**: In the code below, I have provided weights and data, and a loop which goes through and tries to predict the incoming sequence. You need to write the predict function based on the equations above, and the predict function needs to return $y_{t+1}$ and $x_{t+1}$. You can use any choice of activation function $f$. \n",
        "\n",
        "**Tips** You can use `torch.cat` to concatenate togther $x$ and $y$ (denoted $[x, y]$ above). For instance, `torch.cat((x, hidden), 1)` will concatenate the matrices along the 1st dimension. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqv6HLWuGgVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6336acd2-b28b-4757-dd0c-11579091fb3c"
      },
      "source": [
        "# Provides extra neural network functions\n",
        "import torch.nn as nn\n",
        "\n",
        "# define size of h\n",
        "hidden_size = 6\n",
        "# define size of x\n",
        "input_size = 1\n",
        "# length of data we model\n",
        "seq_len = 20\n",
        "\n",
        "# define a sequence of y data\n",
        "y_data = torch.rand(seq_len)\n",
        "\n",
        "# Define our weights \n",
        "W_1 = nn.Parameter(torch.rand(hidden_size + input_size, hidden_size)).float()\n",
        "W_2 = nn.Parameter(torch.rand(hidden_size, input_size)).float()\n",
        "\n",
        "\n",
        "# Define our predict function (todo)\n",
        "def predict(y, x, W_1, W_2):\n",
        "    # answer\n",
        "    x_and_y = torch.cat((x, y), 1)\n",
        "    hidden = torch.tanh(torch.mm(x_and_y, W_1))\n",
        "    out = torch.mm(hidden, W_2)\n",
        "    return out, hidden\n",
        "\n",
        "# init hidden state\n",
        "x_t = torch.zeros((1, hidden_size))\n",
        "\n",
        "# loop over sequence\n",
        "for t in range(seq_len):\n",
        "    y_t = y_data[t].view(1, 1)\n",
        "    y_t_hat, hidden = predict(y_t, x_t, W_1, W_2)\n",
        "    assert (list(y_t_hat.size()) == [1, input_size]), \"wrong size for y\"\n",
        "    assert (list(hidden.size()) == [1, hidden_size]), \"wrong size for h\"\n",
        "print(\"Well done, your predict function was correct\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done, your predict function was correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy1UYbD5ILiH"
      },
      "source": [
        "## 5.c Sequence learning __(Optional)__\n",
        "\n",
        "To train a recurrent neural network, we measure the loss for each prediction in a sequence, add together these losses for the whole sequence, and backproagate. \n",
        "\n",
        "> **Task**: Below is code which performs a training and test loop for a recurrent neural networked trained to predict a sine wave. Fill in the missing components, and try experimenting with testing: what happens when you only pass in part of a sequence (and use the networks own predictions as data for the next time step)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ohEbmF3Jap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "771412c1-8995-45c8-8db0-18b616ba73ba"
      },
      "source": [
        "# Provides extra neural network functions\n",
        "import torch.nn as nn\n",
        "# Provides optimizers\n",
        "import torch.optim as optim\n",
        "\n",
        "# define constants\n",
        "epochs = 300\n",
        "hidden_size = 6\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "seq_len = 20\n",
        "\n",
        "# Define our sin wave data\n",
        "data_time_steps = np.linspace(2, 10, seq_len + 1)\n",
        "data = np.sin(data_time_steps)\n",
        "\n",
        "# define our sequence\n",
        "x_data = torch.tensor(data[:-1]).float()\n",
        "y_data = torch.tensor(data[1:]).float()\n",
        "\n",
        "# Define our weights (todo)\n",
        "W_1 = nn.Parameter(torch.rand(hidden_size + input_size, hidden_size)).float()\n",
        "W_2 = nn.Parameter(torch.rand(hidden_size, output_size)).float()\n",
        "\n",
        "# Setup our loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Setup our optimizer\n",
        "optimizer = optim.SGD([W_1, W_2], lr=0.01)\n",
        "\n",
        "# Define our predict function (todo)\n",
        "def predict(x, hidden, W_1, W_2):\n",
        "    x_and_hidden = torch.cat((x, hidden), 1)\n",
        "    hidden = torch.tanh(torch.mm(x_and_hidden, W_1))\n",
        "    out = torch.mm(hidden, W_2)\n",
        "    return out, hidden\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    # init hidden state\n",
        "    hidden = torch.zeros((1, hidden_size))\n",
        "    loss = 0\n",
        "    for t in range(x_data.size(0)):\n",
        "        x_t = x_data[t].view(1, 1)\n",
        "        y_t = y_data[t].view(1, 1)\n",
        "        # predict next hidden and state\n",
        "        (y_t_hat, hidden) = predict(x_t, hidden, W_1, W_2)\n",
        "        # accumulate loss\n",
        "        loss = loss + loss_fn(y_t_hat, y_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()  \n",
        "\n",
        "# Test network\n",
        "hidden = torch.zeros((1, hidden_size))\n",
        "predictions = []\n",
        "\n",
        "for t in range(x_data.size(0)):\n",
        "    x_t = x_data[t].view(-1, 1)\n",
        "    (y_t_hat, hidden) = predict(x_t, hidden, W_1, W_2)\n",
        "    predictions.append(y_t_hat.data.numpy().ravel()[0])\n",
        "\n",
        "plt.scatter(data_time_steps[:-1], x_data.data.numpy(), s=90, label=\"Actual\")\n",
        "plt.scatter(data_time_steps[1:], predictions, label=\"Predicted\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "        \n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}